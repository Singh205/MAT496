{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a672f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    \n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bebb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",   \n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6161ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def angry() -> str:\n",
    "    \"\"\" Call this tool if the mood is angry\"\"\"\n",
    "    return \"GUNS BLAZING RAMBO\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sad() -> str:\n",
    "    \"\"\" Call this tool if you want to show sad, depressed, or negative feelings\"\"\"\n",
    "    return \"time to forget and move onðŸ¤•\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def happy() -> str:\n",
    "    \"\"\" Call this tool if you want to show happiness or positive feeling\"\"\"\n",
    "    return \"Miska Muska Mickeyyyyy Mouseee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a8ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [angry, sad, happy ]\n",
    "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4529b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a tool calling Agent by binding a list of tools to the llm\n",
    "llm_with_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6980fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "# This will store all converation\n",
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "690ef73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"World has so much crime and hatred\"))\n",
    "\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef78c598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c06af4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Someone drank my protein shake and i am really irritated by that!\" We need to respond appropriately. The user is irritated. We should show empathy and maybe suggest ways to handle. According to the developer instructions, we should respond the question, or show angry or sad emotions, or be happy with the situation. The user is irritated, so maybe sad or angry? The user is irritated, not necessarily angry. But we can show empathy. According to instructions, \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is upset. We should respond with empathy and maybe a sad or angry tone. The user is irritated, so perhaps we can show sad or angry. We might choose sad because it\\'s about irritation. But the user didn\\'t explicitly ask for advice; they just expressed irritation. We can respond with a sad or angry response. Maybe a sad response: \"I\\'m sorry to hear that. That can be frustrating.\" Or an angry response? The user is irritated, but not necessarily angry. We can choose sad. The instructions: \"Call this tool if you want to show sad, depressed, or negative feelings\". So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_941b59ac-464e-42cb-a788-81bae6eabaa3', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 342, 'total_tokens': 616, 'completion_time': 0.247171929, 'prompt_time': 0.022326422, 'queue_time': 0.054298308, 'total_time': 0.269498351}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--371d0bff-9201-4ad9-90c0-317b28cfe41c-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_941b59ac-464e-42cb-a788-81bae6eabaa3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 342, 'output_tokens': 274, 'total_tokens': 616})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"Someone drank my protein shake and i am really irritated by that!\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d150fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391}),\n",
       " HumanMessage(content='Hitler wiped out the jews!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Hitler wiped out the jews!\" This is a statement. The user is presumably making a statement. According to the instructions, \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is stating a historical fact. The bot should respond appropriately. But we must consider policy. This is a statement about genocide. The user is not asking a question. There\\'s no request for disallowed content. The user is stating a historical fact. The bot should respond. There\\'s no disallowed content. The user is not requesting hateful content. The user is not praising the genocide. They are simply stating. The assistant should respond. According to policy, the assistant can respond with a factual statement. The user is basically making a statement about the Holocaust. The assistant should respond with empathy, perhaps acknowledging the seriousness, but not praising or supporting. The user is not requesting disallowed content. So we can comply. We can respond with a neutral or factual tone, possibly acknowledging the seriousness. The user statement: \"Hitler wiped out the jews!\" It\\'s an offensive statement but it\\'s a historical fact. The user is not requesting disallowed content. The assistant should respond with empathy, acknowledging the tragedy. There\\'s no hate content to be censored. We can comply. The user might want an answer. The user didn\\'t ask a question. The instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" The user didn\\'t ask a question. The user made a statement. We can respond with a sad emotional response. Possibly we can use the sad function. The user says \"Hitler wiped out the jews!\" It\\'s a sad statement. We can respond with a sad emotion. So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 230, 'total_tokens': 636, 'completion_time': 0.361491839, 'prompt_time': 0.014940319, 'queue_time': 0.053299251, 'total_time': 0.376432158}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87ebb2fe-3399-424e-aa74-ca8d7cd4e09b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 406, 'total_tokens': 636})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c86fd4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391}),\n",
       " HumanMessage(content='Hitler wiped out the jews!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Hitler wiped out the jews!\" This is a statement. The user is presumably making a statement. According to the instructions, \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is stating a historical fact. The bot should respond appropriately. But we must consider policy. This is a statement about genocide. The user is not asking a question. There\\'s no request for disallowed content. The user is stating a historical fact. The bot should respond. There\\'s no disallowed content. The user is not requesting hateful content. The user is not praising the genocide. They are simply stating. The assistant should respond. According to policy, the assistant can respond with a factual statement. The user is basically making a statement about the Holocaust. The assistant should respond with empathy, perhaps acknowledging the seriousness, but not praising or supporting. The user is not requesting disallowed content. So we can comply. We can respond with a neutral or factual tone, possibly acknowledging the seriousness. The user statement: \"Hitler wiped out the jews!\" It\\'s an offensive statement but it\\'s a historical fact. The user is not requesting disallowed content. The assistant should respond with empathy, acknowledging the tragedy. There\\'s no hate content to be censored. We can comply. The user might want an answer. The user didn\\'t ask a question. The instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" The user didn\\'t ask a question. The user made a statement. We can respond with a sad emotional response. Possibly we can use the sad function. The user says \"Hitler wiped out the jews!\" It\\'s a sad statement. We can respond with a sad emotion. So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 230, 'total_tokens': 636, 'completion_time': 0.361491839, 'prompt_time': 0.014940319, 'queue_time': 0.053299251, 'total_time': 0.376432158}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87ebb2fe-3399-424e-aa74-ca8d7cd4e09b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 406, 'total_tokens': 636}),\n",
       " ToolMessage(content='time to forget and move onðŸ¤•', name='sad', tool_call_id='fc_113ba588-af74-4c2a-828b-9429d5d6519a')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7d7cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391}),\n",
       " HumanMessage(content='Hitler wiped out the jews!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Hitler wiped out the jews!\" This is a statement. The user is presumably making a statement. According to the instructions, \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is stating a historical fact. The bot should respond appropriately. But we must consider policy. This is a statement about genocide. The user is not asking a question. There\\'s no request for disallowed content. The user is stating a historical fact. The bot should respond. There\\'s no disallowed content. The user is not requesting hateful content. The user is not praising the genocide. They are simply stating. The assistant should respond. According to policy, the assistant can respond with a factual statement. The user is basically making a statement about the Holocaust. The assistant should respond with empathy, perhaps acknowledging the seriousness, but not praising or supporting. The user is not requesting disallowed content. So we can comply. We can respond with a neutral or factual tone, possibly acknowledging the seriousness. The user statement: \"Hitler wiped out the jews!\" It\\'s an offensive statement but it\\'s a historical fact. The user is not requesting disallowed content. The assistant should respond with empathy, acknowledging the tragedy. There\\'s no hate content to be censored. We can comply. The user might want an answer. The user didn\\'t ask a question. The instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" The user didn\\'t ask a question. The user made a statement. We can respond with a sad emotional response. Possibly we can use the sad function. The user says \"Hitler wiped out the jews!\" It\\'s a sad statement. We can respond with a sad emotion. So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 230, 'total_tokens': 636, 'completion_time': 0.361491839, 'prompt_time': 0.014940319, 'queue_time': 0.053299251, 'total_time': 0.376432158}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87ebb2fe-3399-424e-aa74-ca8d7cd4e09b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 406, 'total_tokens': 636}),\n",
       " ToolMessage(content='time to forget and move onðŸ¤•', name='sad', tool_call_id='fc_113ba588-af74-4c2a-828b-9429d5d6519a'),\n",
       " HumanMessage(content='i met mickey mouse today', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"i met mickey mouse today\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5573707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391}),\n",
       " HumanMessage(content='Hitler wiped out the jews!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Hitler wiped out the jews!\" This is a statement. The user is presumably making a statement. According to the instructions, \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is stating a historical fact. The bot should respond appropriately. But we must consider policy. This is a statement about genocide. The user is not asking a question. There\\'s no request for disallowed content. The user is stating a historical fact. The bot should respond. There\\'s no disallowed content. The user is not requesting hateful content. The user is not praising the genocide. They are simply stating. The assistant should respond. According to policy, the assistant can respond with a factual statement. The user is basically making a statement about the Holocaust. The assistant should respond with empathy, perhaps acknowledging the seriousness, but not praising or supporting. The user is not requesting disallowed content. So we can comply. We can respond with a neutral or factual tone, possibly acknowledging the seriousness. The user statement: \"Hitler wiped out the jews!\" It\\'s an offensive statement but it\\'s a historical fact. The user is not requesting disallowed content. The assistant should respond with empathy, acknowledging the tragedy. There\\'s no hate content to be censored. We can comply. The user might want an answer. The user didn\\'t ask a question. The instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" The user didn\\'t ask a question. The user made a statement. We can respond with a sad emotional response. Possibly we can use the sad function. The user says \"Hitler wiped out the jews!\" It\\'s a sad statement. We can respond with a sad emotion. So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 230, 'total_tokens': 636, 'completion_time': 0.361491839, 'prompt_time': 0.014940319, 'queue_time': 0.053299251, 'total_time': 0.376432158}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87ebb2fe-3399-424e-aa74-ca8d7cd4e09b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 406, 'total_tokens': 636}),\n",
       " ToolMessage(content='time to forget and move onðŸ¤•', name='sad', tool_call_id='fc_113ba588-af74-4c2a-828b-9429d5d6519a'),\n",
       " HumanMessage(content='i met mickey mouse today', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58d0d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391}),\n",
       " HumanMessage(content='Hitler wiped out the jews!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Hitler wiped out the jews!\" This is a statement. The user is presumably making a statement. According to the instructions, \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is stating a historical fact. The bot should respond appropriately. But we must consider policy. This is a statement about genocide. The user is not asking a question. There\\'s no request for disallowed content. The user is stating a historical fact. The bot should respond. There\\'s no disallowed content. The user is not requesting hateful content. The user is not praising the genocide. They are simply stating. The assistant should respond. According to policy, the assistant can respond with a factual statement. The user is basically making a statement about the Holocaust. The assistant should respond with empathy, perhaps acknowledging the seriousness, but not praising or supporting. The user is not requesting disallowed content. So we can comply. We can respond with a neutral or factual tone, possibly acknowledging the seriousness. The user statement: \"Hitler wiped out the jews!\" It\\'s an offensive statement but it\\'s a historical fact. The user is not requesting disallowed content. The assistant should respond with empathy, acknowledging the tragedy. There\\'s no hate content to be censored. We can comply. The user might want an answer. The user didn\\'t ask a question. The instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" The user didn\\'t ask a question. The user made a statement. We can respond with a sad emotional response. Possibly we can use the sad function. The user says \"Hitler wiped out the jews!\" It\\'s a sad statement. We can respond with a sad emotion. So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 230, 'total_tokens': 636, 'completion_time': 0.361491839, 'prompt_time': 0.014940319, 'queue_time': 0.053299251, 'total_time': 0.376432158}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87ebb2fe-3399-424e-aa74-ca8d7cd4e09b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 406, 'total_tokens': 636}),\n",
       " ToolMessage(content='time to forget and move onðŸ¤•', name='sad', tool_call_id='fc_113ba588-af74-4c2a-828b-9429d5d6519a'),\n",
       " HumanMessage(content='i met mickey mouse today', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356}),\n",
       " ToolMessage(content='Miska Muska Mickeyyyyy Mouseee', name='happy', tool_call_id='fc_9d5ed168-4916-4ad0-a790-478a3583cab4')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23deaa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World has so much crime and hatred', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond. The user says: \"World has so much crime and hatred\". According to instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user statement expresses concern about crime and hatred. We should respond with an appropriate emotional tone. Likely sad or angry? The user expresses a negative observation. We could show empathy and sadness or anger. The instructions: \"either respond the question, or show angry or sad emotions, or be happy with the situation\". There\\'s no question. So we either respond or show emotion. Probably show sad or angry. I\\'d choose sad, as it\\'s a global issue. So we call sad().\\n\\nWe should output a function call to sad with no arguments.', 'tool_calls': [{'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 207, 'total_tokens': 391, 'completion_time': 0.167414558, 'prompt_time': 0.013498854, 'queue_time': 0.046707156, 'total_time': 0.180913412}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dacd6b8f-759c-4a78-bf15-a4672b18766b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_e38ca692-c6b1-46f7-949a-da59a89a1bef', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 184, 'total_tokens': 391}),\n",
       " HumanMessage(content='Hitler wiped out the jews!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'The user says \"Hitler wiped out the jews!\" This is a statement. The user is presumably making a statement. According to the instructions, \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". The user is stating a historical fact. The bot should respond appropriately. But we must consider policy. This is a statement about genocide. The user is not asking a question. There\\'s no request for disallowed content. The user is stating a historical fact. The bot should respond. There\\'s no disallowed content. The user is not requesting hateful content. The user is not praising the genocide. They are simply stating. The assistant should respond. According to policy, the assistant can respond with a factual statement. The user is basically making a statement about the Holocaust. The assistant should respond with empathy, perhaps acknowledging the seriousness, but not praising or supporting. The user is not requesting disallowed content. So we can comply. We can respond with a neutral or factual tone, possibly acknowledging the seriousness. The user statement: \"Hitler wiped out the jews!\" It\\'s an offensive statement but it\\'s a historical fact. The user is not requesting disallowed content. The assistant should respond with empathy, acknowledging the tragedy. There\\'s no hate content to be censored. We can comply. The user might want an answer. The user didn\\'t ask a question. The instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" The user didn\\'t ask a question. The user made a statement. We can respond with a sad emotional response. Possibly we can use the sad function. The user says \"Hitler wiped out the jews!\" It\\'s a sad statement. We can respond with a sad emotion. So we should call the sad function. Let\\'s do that.', 'tool_calls': [{'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 230, 'total_tokens': 636, 'completion_time': 0.361491839, 'prompt_time': 0.014940319, 'queue_time': 0.053299251, 'total_time': 0.376432158}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87ebb2fe-3399-424e-aa74-ca8d7cd4e09b-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_113ba588-af74-4c2a-828b-9429d5d6519a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 406, 'total_tokens': 636}),\n",
       " ToolMessage(content='time to forget and move onðŸ¤•', name='sad', tool_call_id='fc_113ba588-af74-4c2a-828b-9429d5d6519a'),\n",
       " HumanMessage(content='i met mickey mouse today', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to respond with appropriate emotion: user said \"i met mickey mouse today\". That seems positive. According to instruction: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation\". This is a positive situation. So we should show happiness. Use the happy function.', 'tool_calls': [{'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 268, 'total_tokens': 356, 'completion_time': 0.078331566, 'prompt_time': 0.017467142, 'queue_time': 0.053701578, 'total_time': 0.095798708}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_b30a5b183c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a60c12ae-9258-46f2-ac1e-3dec0c177af3-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'fc_9d5ed168-4916-4ad0-a790-478a3583cab4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 268, 'output_tokens': 88, 'total_tokens': 356}),\n",
       " ToolMessage(content='Miska Muska Mickeyyyyy Mouseee', name='happy', tool_call_id='fc_9d5ed168-4916-4ad0-a790-478a3583cab4'),\n",
       " HumanMessage(content='My girlfriend cheated', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': 'We have a conversation. The user says \"My girlfriend cheated\". We need to respond. The instructions: \"You are a bot with emotions. Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" So we need to respond with an emotional tone appropriate. The user says \"My girlfriend cheated\". That is a sensitive situation. Likely we should respond with empathy, sadness, maybe anger. According to guidelines, we should respond with empathy and support, not angry. The user is probably upset. So we should respond with sad or empathy. The instructions say: \"Depending on the conversation, either respond the question, or show angry or sad emotions, or be happy with the situation.\" So we should respond with sad. So we call functions.sad.', 'tool_calls': [{'id': 'fc_a58db9fc-df6a-450e-9dff-040133d89c09', 'function': {'arguments': '{}', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 314, 'total_tokens': 498, 'completion_time': 0.166236788, 'prompt_time': 0.020335862, 'queue_time': 0.051809558, 'total_time': 0.18657265}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_59f77feedf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dc74a0a2-3367-42ec-be62-3e1b9cec7e67-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'fc_a58db9fc-df6a-450e-9dff-040133d89c09', 'type': 'tool_call'}], usage_metadata={'input_tokens': 314, 'output_tokens': 184, 'total_tokens': 498})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"My girlfriend cheated\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
